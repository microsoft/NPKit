Copyright (c) Microsoft Corporation.
Licensed under the MIT License.

diff --git a/src/collectives/device/all_reduce.h b/src/collectives/device/all_reduce.h
index 3b8ae1a..aac673c 100644
--- a/src/collectives/device/all_reduce.h
+++ b/src/collectives/device/all_reduce.h
@@ -8,6 +8,9 @@
 #include "primitives.h"
 #include "collectives.h"
 #include "sccl_interpreter.h"
+#if defined(ENABLE_NPKIT)
+#include "npkit/npkit.h"
+#endif
 
 template<class FUNC, typename T, int UNROLL>
 class ncclFunction<ncclFuncAllReduce, NCCL_ALGO_RING, NCCL_PROTO_SIMPLE, FUNC, T, UNROLL> {
@@ -26,6 +29,28 @@ class ncclFunction<ncclFuncAllReduce, NCCL_ALGO_RING, NCCL_PROTO_SIMPLE, FUNC, T
     const ssize_t loopSize = nChannels*(ssize_t)chunkSize;
     const ssize_t size = args->coll.count;
 
+#if defined(ENABLE_NPKIT) && defined(ENABLE_NPKIT_EVENT_TIME_SYNC_CPU)
+    if (threadIdx.x == 0) {
+      uint64_t* cpuTimestamp = channel->cpuTimestamp;
+      NpKit::GenerateAndCollectGpuEvent(NPKIT_EVENT_TIME_SYNC_CPU, 0, 0, *cpuTimestamp,
+          &(channel->npKitEvent), channel->gpuNpKitEventCollectContext);
+    }
+#endif
+
+#if defined(ENABLE_NPKIT) && defined(ENABLE_NPKIT_EVENT_TIME_SYNC_GPU)
+    if (threadIdx.x == 0) {
+      NpKit::GenerateAndCollectGpuEvent(NPKIT_EVENT_TIME_SYNC_GPU, 0, 0, clock64(),
+          &(channel->npKitEvent), channel->gpuNpKitEventCollectContext);
+    }
+#endif
+
+#if defined(ENABLE_NPKIT) && defined(ENABLE_NPKIT_EVENT_ALL_REDUCE_RING_ENTRY)
+    if (threadIdx.x == 0) {
+      NpKit::GenerateAndCollectGpuEvent(NPKIT_EVENT_ALL_REDUCE_RING_ENTRY, size*sizeof(T), 0, clock64(),
+          &(channel->npKitEvent), channel->gpuNpKitEventCollectContext);
+    }
+#endif
+
     // Compute pointers
     const T * __restrict__ thisInput = (const T*)args->sendbuff;
     T * __restrict__ thisOutput = (T*)args->recvbuff;
@@ -84,6 +109,14 @@ class ncclFunction<ncclFuncAllReduce, NCCL_ALGO_RING, NCCL_PROTO_SIMPLE, FUNC, T
       // Final wait/copy.
       prims.directRecv(thisOutput+offset, offset, nelem);
     }
+
+#if defined(ENABLE_NPKIT) && defined(ENABLE_NPKIT_EVENT_ALL_REDUCE_RING_EXIT)
+    if (threadIdx.x == 0) {
+      NpKit::GenerateAndCollectGpuEvent(NPKIT_EVENT_ALL_REDUCE_RING_EXIT, size*sizeof(T), 0, clock64(),
+          &(channel->npKitEvent), channel->gpuNpKitEventCollectContext);
+    }
+#endif
+
   }
 };
 
@@ -104,6 +137,28 @@ class ncclFunction<ncclFuncAllReduce, NCCL_ALGO_TREE, NCCL_PROTO_SIMPLE, FUNC, T
     const ssize_t loopSize = nChannels*chunkSize;
     const ssize_t size = args->coll.count;
 
+#if defined(ENABLE_NPKIT) && defined(ENABLE_NPKIT_EVENT_TIME_SYNC_CPU)
+    if (threadIdx.x == 0) {
+      uint64_t* cpuTimestamp = channel->cpuTimestamp;
+      NpKit::GenerateAndCollectGpuEvent(NPKIT_EVENT_TIME_SYNC_CPU, 0, 0, *cpuTimestamp,
+          &(channel->npKitEvent), channel->gpuNpKitEventCollectContext);
+    }
+#endif
+
+#if defined(ENABLE_NPKIT) && defined(ENABLE_NPKIT_EVENT_TIME_SYNC_GPU)
+    if (threadIdx.x == 0) {
+      NpKit::GenerateAndCollectGpuEvent(NPKIT_EVENT_TIME_SYNC_GPU, 0, 0, clock64(),
+          &(channel->npKitEvent), channel->gpuNpKitEventCollectContext);
+    }
+#endif
+
+#if defined(ENABLE_NPKIT) && defined(ENABLE_NPKIT_EVENT_ALL_REDUCE_TREE_UPDOWN_ENTRY)
+    if (threadIdx.x == 0) {
+      NpKit::GenerateAndCollectGpuEvent(NPKIT_EVENT_ALL_REDUCE_TREE_UPDOWN_ENTRY, size*sizeof(T), 0, clock64(),
+          &(channel->npKitEvent), channel->gpuNpKitEventCollectContext);
+    }
+#endif
+
     if (loopSize > size) {
       chunkSize = DIVUP(size, nChannels*minChunkSize)*minChunkSize;
     }
@@ -194,6 +249,14 @@ class ncclFunction<ncclFuncAllReduce, NCCL_ALGO_TREE, NCCL_PROTO_SIMPLE, FUNC, T
       }
     }
 #endif
+
+#if defined(ENABLE_NPKIT) && defined(ENABLE_NPKIT_EVENT_ALL_REDUCE_TREE_UPDOWN_EXIT)
+    if (threadIdx.x == 0) {
+      NpKit::GenerateAndCollectGpuEvent(NPKIT_EVENT_ALL_REDUCE_TREE_UPDOWN_EXIT, size*sizeof(T), 0, clock64(),
+          &(channel->npKitEvent), channel->gpuNpKitEventCollectContext);
+    }
+#endif
+
   }
 };
 
@@ -276,6 +339,28 @@ class ncclFunction<ncclFuncAllReduce, NCCL_ALGO_RING, NCCL_PROTO_LL, FUNC, T, UN
     const ssize_t loopSize = nChannels*nranks*chunkSize;
     const ssize_t size = args->coll.count;
 
+#if defined(ENABLE_NPKIT) && defined(ENABLE_NPKIT_EVENT_TIME_SYNC_CPU)
+    if (threadIdx.x == 0) {
+      uint64_t* cpuTimestamp = channel->cpuTimestamp;
+      NpKit::GenerateAndCollectGpuEvent(NPKIT_EVENT_TIME_SYNC_CPU, 0, 0, *cpuTimestamp,
+          &(channel->npKitEvent), channel->gpuNpKitEventCollectContext);
+    }
+#endif
+
+#if defined(ENABLE_NPKIT) && defined(ENABLE_NPKIT_EVENT_TIME_SYNC_GPU)
+    if (threadIdx.x == 0) {
+      NpKit::GenerateAndCollectGpuEvent(NPKIT_EVENT_TIME_SYNC_GPU, 0, 0, clock64(),
+          &(channel->npKitEvent), channel->gpuNpKitEventCollectContext);
+    }
+#endif
+
+#if defined(ENABLE_NPKIT) && defined(ENABLE_NPKIT_EVENT_ALL_REDUCE_RING_ENTRY)
+    if (threadIdx.x == 0) {
+      NpKit::GenerateAndCollectGpuEvent(NPKIT_EVENT_ALL_REDUCE_RING_ENTRY, size*sizeof(T), 0, clock64(),
+          &(channel->npKitEvent), channel->gpuNpKitEventCollectContext);
+    }
+#endif
+
     ncclLLPrimitives<T, FUNC, 1, 1> LLprims(tid, nthreads, &ring->prev, &ring->next, stepLines, channel, comm);
 
     // Compute pointers
@@ -331,6 +416,14 @@ class ncclFunction<ncclFuncAllReduce, NCCL_ALGO_RING, NCCL_PROTO_LL, FUNC, T, UN
       // Here we need to copy from buffer to this output.
       LLprims.recv(thisOutput+offset, nelem);
     }
+
+#if defined(ENABLE_NPKIT) && defined(ENABLE_NPKIT_EVENT_ALL_REDUCE_RING_EXIT)
+    if (threadIdx.x == 0) {
+      NpKit::GenerateAndCollectGpuEvent(NPKIT_EVENT_ALL_REDUCE_RING_EXIT, size*sizeof(T), 0, clock64(),
+          &(channel->npKitEvent), channel->gpuNpKitEventCollectContext);
+    }
+#endif
+
   }
 };
 
@@ -351,6 +444,28 @@ class ncclFunction<ncclFuncAllReduce, NCCL_ALGO_TREE, NCCL_PROTO_LL, FUNC, T, UN
     const ssize_t loopSize = nChannels*chunkSize;
     const ssize_t size = args->coll.count;
 
+#if defined(ENABLE_NPKIT) && defined(ENABLE_NPKIT_EVENT_TIME_SYNC_CPU)
+    if (threadIdx.x == 0) {
+      uint64_t* cpuTimestamp = channel->cpuTimestamp;
+      NpKit::GenerateAndCollectGpuEvent(NPKIT_EVENT_TIME_SYNC_CPU, 0, 0, *cpuTimestamp,
+          &(channel->npKitEvent), channel->gpuNpKitEventCollectContext);
+    }
+#endif
+
+#if defined(ENABLE_NPKIT) && defined(ENABLE_NPKIT_EVENT_TIME_SYNC_GPU)
+    if (threadIdx.x == 0) {
+      NpKit::GenerateAndCollectGpuEvent(NPKIT_EVENT_TIME_SYNC_GPU, 0, 0, clock64(),
+          &(channel->npKitEvent), channel->gpuNpKitEventCollectContext);
+    }
+#endif
+
+#if defined(ENABLE_NPKIT) && defined(ENABLE_NPKIT_EVENT_ALL_REDUCE_TREE_UPDOWN_ENTRY)
+    if (threadIdx.x == 0) {
+      NpKit::GenerateAndCollectGpuEvent(NPKIT_EVENT_ALL_REDUCE_TREE_UPDOWN_ENTRY, size*sizeof(T), 0, clock64(),
+          &(channel->npKitEvent), channel->gpuNpKitEventCollectContext);
+    }
+#endif
+
     if (loopSize > size) {
       chunkSize = DIVUP(size, nChannels*minChunkSize)*minChunkSize;
     }
@@ -392,6 +507,14 @@ class ncclFunction<ncclFuncAllReduce, NCCL_ALGO_TREE, NCCL_PROTO_LL, FUNC, T, UN
         }
       }
     } while(0);
+
+#if defined(ENABLE_NPKIT) && defined(ENABLE_NPKIT_EVENT_ALL_REDUCE_TREE_UPDOWN_EXIT)
+    if (threadIdx.x == 0) {
+      NpKit::GenerateAndCollectGpuEvent(NPKIT_EVENT_ALL_REDUCE_TREE_UPDOWN_EXIT, size*sizeof(T), 0, clock64(),
+          &(channel->npKitEvent), channel->gpuNpKitEventCollectContext);
+    }
+#endif
+
   }
 };
 
@@ -473,6 +596,28 @@ class ncclFunction<ncclFuncAllReduce, NCCL_ALGO_RING, NCCL_PROTO_LL128, FUNC, T,
     const ssize_t loopSize = nChannels*nranks*chunkSize;
     const ssize_t size = args->coll.count;
 
+#if defined(ENABLE_NPKIT) && defined(ENABLE_NPKIT_EVENT_TIME_SYNC_CPU)
+    if (threadIdx.x == 0) {
+      uint64_t* cpuTimestamp = channel->cpuTimestamp;
+      NpKit::GenerateAndCollectGpuEvent(NPKIT_EVENT_TIME_SYNC_CPU, 0, 0, *cpuTimestamp,
+          &(channel->npKitEvent), channel->gpuNpKitEventCollectContext);
+    }
+#endif
+
+#if defined(ENABLE_NPKIT) && defined(ENABLE_NPKIT_EVENT_TIME_SYNC_GPU)
+    if (threadIdx.x == 0) {
+      NpKit::GenerateAndCollectGpuEvent(NPKIT_EVENT_TIME_SYNC_GPU, 0, 0, clock64(),
+          &(channel->npKitEvent), channel->gpuNpKitEventCollectContext);
+    }
+#endif
+
+#if defined(ENABLE_NPKIT) && defined(ENABLE_NPKIT_EVENT_ALL_REDUCE_RING_ENTRY)
+    if (threadIdx.x == 0) {
+      NpKit::GenerateAndCollectGpuEvent(NPKIT_EVENT_ALL_REDUCE_RING_ENTRY, size*sizeof(T), 0, clock64(),
+          &(channel->npKitEvent), channel->gpuNpKitEventCollectContext);
+    }
+#endif
+
     ncclLL128Primitives<T, FUNC, 1, 1> LLprims(tid, nthreads, &ring->prev, &ring->next, stepSize, channel, comm);
 
     // Compute pointers
@@ -528,6 +673,14 @@ class ncclFunction<ncclFuncAllReduce, NCCL_ALGO_RING, NCCL_PROTO_LL128, FUNC, T,
       // Here we need to copy from buffer to this output.
       LLprims.recv(thisOutput+offset, nelem);
     }
+
+#if defined(ENABLE_NPKIT) && defined(ENABLE_NPKIT_EVENT_ALL_REDUCE_RING_EXIT)
+    if (threadIdx.x == 0) {
+      NpKit::GenerateAndCollectGpuEvent(NPKIT_EVENT_ALL_REDUCE_RING_EXIT, size*sizeof(T), 0, clock64(),
+          &(channel->npKitEvent), channel->gpuNpKitEventCollectContext);
+    }
+#endif
+
   }
 };
 
@@ -549,6 +702,40 @@ class ncclFunction<ncclFuncAllReduce, NCCL_ALGO_TREE, NCCL_PROTO_LL128, FUNC, T,
     int nthreadsSplit = NCCL_LL128_SPLIT(nthreads);
     const ssize_t size = args->coll.count;
 
+#if defined(ENABLE_NPKIT) && defined(ENABLE_NPKIT_EVENT_TIME_SYNC_CPU)
+#if defined(ENABLE_NPKIT_THREAD_SPLIT_SECOND_HALF)
+    if (threadIdx.x == nthreadsSplit) {
+#else
+    if (threadIdx.x == 0) {
+#endif
+      uint64_t* cpuTimestamp = channel->cpuTimestamp;
+      NpKit::GenerateAndCollectGpuEvent(NPKIT_EVENT_TIME_SYNC_CPU, 0, 0, *cpuTimestamp,
+          &(channel->npKitEvent), channel->gpuNpKitEventCollectContext);
+    }
+#endif
+
+#if defined(ENABLE_NPKIT) && defined(ENABLE_NPKIT_EVENT_TIME_SYNC_GPU)
+#if defined(ENABLE_NPKIT_THREAD_SPLIT_SECOND_HALF)
+    if (threadIdx.x == nthreadsSplit) {
+#else
+    if (threadIdx.x == 0) {
+#endif
+      NpKit::GenerateAndCollectGpuEvent(NPKIT_EVENT_TIME_SYNC_GPU, 0, 0, clock64(),
+          &(channel->npKitEvent), channel->gpuNpKitEventCollectContext);
+    }
+#endif
+
+#if defined(ENABLE_NPKIT) && defined(ENABLE_NPKIT_EVENT_ALL_REDUCE_TREE_SPLIT_ENTRY)
+#if defined(ENABLE_NPKIT_THREAD_SPLIT_SECOND_HALF)
+    if (threadIdx.x == nthreadsSplit) {
+#else
+    if (threadIdx.x == 0) {
+#endif
+      NpKit::GenerateAndCollectGpuEvent(NPKIT_EVENT_ALL_REDUCE_TREE_SPLIT_ENTRY, size*sizeof(T), 0, clock64(),
+          &(channel->npKitEvent), channel->gpuNpKitEventCollectContext);
+    }
+#endif
+
     if (loopSize > size) {
       chunkSize = DIVUP(size, nChannels*minChunkSize)*minChunkSize;
     }
@@ -594,6 +781,18 @@ class ncclFunction<ncclFuncAllReduce, NCCL_ALGO_TREE, NCCL_PROTO_LL128, FUNC, T,
         }
       }
     }
+
+#if defined(ENABLE_NPKIT) && defined(ENABLE_NPKIT_EVENT_ALL_REDUCE_TREE_SPLIT_ENTRY)
+#if defined(ENABLE_NPKIT_THREAD_SPLIT_SECOND_HALF)
+    if (threadIdx.x == nthreadsSplit) {
+#else
+    if (threadIdx.x == 0) {
+#endif
+      NpKit::GenerateAndCollectGpuEvent(NPKIT_EVENT_ALL_REDUCE_TREE_SPLIT_ENTRY, size*sizeof(T), 0, clock64(),
+          &(channel->npKitEvent), channel->gpuNpKitEventCollectContext);
+    }
+#endif
+
   }
 };
 
